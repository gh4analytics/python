{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "1. Split dataset\n",
    "2. Build model pipelines\n",
    "3. Declare hyperparameters to tune\n",
    "4. Fit and tune models with cross-validation\n",
    "5. Evaluate metrics and select winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load ML libraries\n",
    "\n",
    "# ElasticNet, Ridge, Lasso\n",
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "\n",
    "# Randomforest, Gradient Boosted Trees\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1863, 40)\n"
     ]
    }
   ],
   "source": [
    "#Load cleaned dataset\n",
    "\n",
    "df = pd.read_csv('project_files/backup_analytical_base_table.csv')\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#target variable\n",
    "y = df.tx_price\n",
    "\n",
    "#input features\n",
    "X = df.drop('tx_price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split X and y into train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490 373 1490 373\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test), len(y_train), len(y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>property_age</th>\n",
       "      <th>school_score</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.434</td>\n",
       "      <td>2.579</td>\n",
       "      <td>2322.785</td>\n",
       "      <td>12746.660</td>\n",
       "      <td>0.879</td>\n",
       "      <td>39.496</td>\n",
       "      <td>4.389</td>\n",
       "      <td>5.005</td>\n",
       "      <td>5.186</td>\n",
       "      <td>39.561</td>\n",
       "      <td>3.362</td>\n",
       "      <td>22.909</td>\n",
       "      <td>15.770</td>\n",
       "      <td>38.509</td>\n",
       "      <td>69.471</td>\n",
       "      <td>65.013</td>\n",
       "      <td>464.266</td>\n",
       "      <td>139.610</td>\n",
       "      <td>6.510</td>\n",
       "      <td>2.779</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.266</td>\n",
       "      <td>24.344</td>\n",
       "      <td>-3.731</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.073</td>\n",
       "      <td>0.930</td>\n",
       "      <td>1297.102</td>\n",
       "      <td>34805.545</td>\n",
       "      <td>0.327</td>\n",
       "      <td>46.986</td>\n",
       "      <td>4.498</td>\n",
       "      <td>8.442</td>\n",
       "      <td>7.443</td>\n",
       "      <td>52.335</td>\n",
       "      <td>4.694</td>\n",
       "      <td>25.724</td>\n",
       "      <td>17.999</td>\n",
       "      <td>6.615</td>\n",
       "      <td>19.865</td>\n",
       "      <td>17.093</td>\n",
       "      <td>227.250</td>\n",
       "      <td>71.511</td>\n",
       "      <td>1.975</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.442</td>\n",
       "      <td>21.209</td>\n",
       "      <td>2.115</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>500.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>88.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1351.000</td>\n",
       "      <td>1542.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>59.000</td>\n",
       "      <td>53.250</td>\n",
       "      <td>321.000</td>\n",
       "      <td>94.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>-5.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1913.500</td>\n",
       "      <td>6183.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>426.000</td>\n",
       "      <td>125.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>-4.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3014.750</td>\n",
       "      <td>11761.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>84.000</td>\n",
       "      <td>78.000</td>\n",
       "      <td>572.000</td>\n",
       "      <td>169.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>-2.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>7842.000</td>\n",
       "      <td>436471.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>266.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>340.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>177.000</td>\n",
       "      <td>94.000</td>\n",
       "      <td>69.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>4508.000</td>\n",
       "      <td>1374.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>114.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          beds    baths     sqft   lot_size  basement  restaurants  groceries  \\\n",
       "count 1490.000 1490.000 1490.000   1490.000  1490.000     1490.000   1490.000   \n",
       "mean     3.434    2.579 2322.785  12746.660     0.879       39.496      4.389   \n",
       "std      1.073    0.930 1297.102  34805.545     0.327       46.986      4.498   \n",
       "min      1.000    1.000  500.000      0.000     0.000        0.000      0.000   \n",
       "25%      3.000    2.000 1351.000   1542.000     1.000        6.000      1.000   \n",
       "50%      4.000    3.000 1913.500   6183.000     1.000       21.000      3.000   \n",
       "75%      4.000    3.000 3014.750  11761.000     1.000       56.000      7.000   \n",
       "max      5.000    6.000 7842.000 436471.000     1.000      266.000     24.000   \n",
       "\n",
       "       nightlife    cafes  shopping  arts_entertainment  beauty_spas  \\\n",
       "count   1490.000 1490.000  1490.000            1490.000     1490.000   \n",
       "mean       5.005    5.186    39.561               3.362       22.909   \n",
       "std        8.442    7.443    52.335               4.694       25.724   \n",
       "min        0.000    0.000     0.000               0.000        0.000   \n",
       "25%        0.000    0.000     6.000               0.000        4.000   \n",
       "50%        2.000    3.000    20.000               2.000       15.000   \n",
       "75%        6.000    6.000    50.000               5.000       35.000   \n",
       "max       53.000   47.000   340.000              35.000      177.000   \n",
       "\n",
       "       active_life  median_age  married  college_grad  property_tax  \\\n",
       "count     1490.000    1490.000 1490.000      1490.000      1490.000   \n",
       "mean        15.770      38.509   69.471        65.013       464.266   \n",
       "std         17.999       6.615   19.865        17.093       227.250   \n",
       "min          0.000      22.000   11.000         5.000        88.000   \n",
       "25%          4.000      33.000   59.000        53.250       321.000   \n",
       "50%         10.000      38.000   74.000        66.000       426.000   \n",
       "75%         21.000      43.000   84.000        78.000       572.000   \n",
       "max         94.000      69.000  100.000       100.000      4508.000   \n",
       "\n",
       "       insurance  median_school  num_schools  two_and_two  during_recession  \\\n",
       "count   1490.000       1490.000     1490.000     1490.000          1490.000   \n",
       "mean     139.610          6.510        2.779        0.093             0.266   \n",
       "std       71.511          1.975        0.517        0.290             0.442   \n",
       "min       30.000          1.000        1.000        0.000             0.000   \n",
       "25%       94.000          5.000        3.000        0.000             0.000   \n",
       "50%      125.000          7.000        3.000        0.000             0.000   \n",
       "75%      169.000          8.000        3.000        0.000             1.000   \n",
       "max     1374.000         10.000        4.000        1.000             1.000   \n",
       "\n",
       "       property_age  school_score  exterior_walls_Brick  \\\n",
       "count      1490.000      1490.000              1490.000   \n",
       "mean         24.344        -3.731                 0.360   \n",
       "std          21.209         2.115                 0.480   \n",
       "min           0.000        -8.000                 0.000   \n",
       "25%           6.000        -5.375                 0.000   \n",
       "50%          20.000        -4.000                 0.000   \n",
       "75%          38.000        -2.000                 1.000   \n",
       "max         114.000         2.000                 1.000   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                     1490.000                    1490.000   \n",
       "mean                         0.024                       0.059   \n",
       "std                          0.154                       0.236   \n",
       "min                          0.000                       0.000   \n",
       "25%                          0.000                       0.000   \n",
       "50%                          0.000                       0.000   \n",
       "75%                          0.000                       0.000   \n",
       "max                          1.000                       1.000   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count              1490.000                1490.000              1490.000   \n",
       "mean                  0.066                   0.119                 0.038   \n",
       "std                   0.248                   0.324                 0.190   \n",
       "min                   0.000                   0.000                 0.000   \n",
       "25%                   0.000                   0.000                 0.000   \n",
       "50%                   0.000                   0.000                 0.000   \n",
       "75%                   0.000                   0.000                 0.000   \n",
       "max                   1.000                   1.000                 1.000   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                            1490.000             1490.000      1490.000   \n",
       "mean                                0.268                0.066         0.073   \n",
       "std                                 0.443                0.248         0.260   \n",
       "min                                 0.000                0.000         0.000   \n",
       "25%                                 0.000                0.000         0.000   \n",
       "50%                                 0.000                0.000         0.000   \n",
       "75%                                 1.000                0.000         0.000   \n",
       "max                                 1.000                1.000         1.000   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing  roof_Other  roof_Shake Shingle  \\\n",
       "count                  1490.000      1490.000    1490.000            1490.000   \n",
       "mean                      0.644         0.189       0.060               0.034   \n",
       "std                       0.479         0.392       0.238               0.180   \n",
       "min                       0.000         0.000       0.000               0.000   \n",
       "25%                       0.000         0.000       0.000               0.000   \n",
       "50%                       1.000         0.000       0.000               0.000   \n",
       "75%                       1.000         0.000       0.000               0.000   \n",
       "max                       1.000         1.000       1.000               1.000   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                     1490.000   \n",
       "mean                                         0.419   \n",
       "std                                          0.494   \n",
       "min                                          0.000   \n",
       "25%                                          0.000   \n",
       "50%                                          0.000   \n",
       "75%                                          1.000   \n",
       "max                                          1.000   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                     1490.000  \n",
       "mean                         0.581  \n",
       "std                          0.494  \n",
       "min                          0.000  \n",
       "25%                          0.000  \n",
       "50%                          1.000  \n",
       "75%                          1.000  \n",
       "max                          1.000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>property_age</th>\n",
       "      <th>school_score</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.269</td>\n",
       "      <td>-1.697</td>\n",
       "      <td>-1.405</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>-2.496</td>\n",
       "      <td>-2.943</td>\n",
       "      <td>-3.511</td>\n",
       "      <td>-1.656</td>\n",
       "      <td>-1.533</td>\n",
       "      <td>-2.790</td>\n",
       "      <td>-3.440</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-1.148</td>\n",
       "      <td>-2.018</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.713</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.641</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.735</td>\n",
       "      <td>-0.654</td>\n",
       "      <td>-0.833</td>\n",
       "      <td>-0.527</td>\n",
       "      <td>-0.688</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>-0.638</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.865</td>\n",
       "      <td>-0.777</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.533</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>1.662</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.818</td>\n",
       "      <td>1.334</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>1.650</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.459</td>\n",
       "      <td>3.676</td>\n",
       "      <td>4.255</td>\n",
       "      <td>12.174</td>\n",
       "      <td>0.372</td>\n",
       "      <td>4.821</td>\n",
       "      <td>4.360</td>\n",
       "      <td>5.685</td>\n",
       "      <td>5.618</td>\n",
       "      <td>5.741</td>\n",
       "      <td>6.741</td>\n",
       "      <td>5.990</td>\n",
       "      <td>4.346</td>\n",
       "      <td>4.609</td>\n",
       "      <td>1.537</td>\n",
       "      <td>2.047</td>\n",
       "      <td>17.794</td>\n",
       "      <td>17.262</td>\n",
       "      <td>1.767</td>\n",
       "      <td>2.360</td>\n",
       "      <td>3.129</td>\n",
       "      <td>1.662</td>\n",
       "      <td>4.227</td>\n",
       "      <td>2.709</td>\n",
       "      <td>1.334</td>\n",
       "      <td>6.353</td>\n",
       "      <td>3.990</td>\n",
       "      <td>3.768</td>\n",
       "      <td>2.714</td>\n",
       "      <td>5.059</td>\n",
       "      <td>1.650</td>\n",
       "      <td>3.768</td>\n",
       "      <td>3.558</td>\n",
       "      <td>0.744</td>\n",
       "      <td>2.069</td>\n",
       "      <td>3.943</td>\n",
       "      <td>5.365</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          beds    baths     sqft  lot_size  basement  restaurants  groceries  \\\n",
       "count 1490.000 1490.000 1490.000  1490.000  1490.000     1490.000   1490.000   \n",
       "mean    -0.000   -0.000    0.000     0.000     0.000        0.000      0.000   \n",
       "std      1.000    1.000    1.000     1.000     1.000        1.000      1.000   \n",
       "min     -2.269   -1.697   -1.405    -0.366    -2.688       -0.841     -0.976   \n",
       "25%     -0.405   -0.622   -0.749    -0.322     0.372       -0.713     -0.753   \n",
       "50%      0.527    0.452   -0.316    -0.189     0.372       -0.394     -0.309   \n",
       "75%      0.527    0.452    0.533    -0.028     0.372        0.351      0.581   \n",
       "max      1.459    3.676    4.255    12.174     0.372        4.821      4.360   \n",
       "\n",
       "       nightlife    cafes  shopping  arts_entertainment  beauty_spas  \\\n",
       "count   1490.000 1490.000  1490.000            1490.000     1490.000   \n",
       "mean       0.000    0.000     0.000              -0.000        0.000   \n",
       "std        1.000    1.000     1.000               1.000        1.000   \n",
       "min       -0.593   -0.697    -0.756              -0.716       -0.891   \n",
       "25%       -0.593   -0.697    -0.641              -0.716       -0.735   \n",
       "50%       -0.356   -0.294    -0.374              -0.290       -0.307   \n",
       "75%        0.118    0.109     0.199               0.349        0.470   \n",
       "max        5.685    5.618     5.741               6.741        5.990   \n",
       "\n",
       "       active_life  median_age  married  college_grad  property_tax  \\\n",
       "count     1490.000    1490.000 1490.000      1490.000      1490.000   \n",
       "mean         0.000      -0.000   -0.000        -0.000         0.000   \n",
       "std          1.000       1.000    1.000         1.000         1.000   \n",
       "min         -0.876      -2.496   -2.943        -3.511        -1.656   \n",
       "25%         -0.654      -0.833   -0.527        -0.688        -0.630   \n",
       "50%         -0.321      -0.077    0.228         0.058        -0.168   \n",
       "75%          0.291       0.679    0.731         0.760         0.474   \n",
       "max          4.346       4.609    1.537         2.047        17.794   \n",
       "\n",
       "       insurance  median_school  num_schools  two_and_two  during_recession  \\\n",
       "count   1490.000       1490.000     1490.000     1490.000          1490.000   \n",
       "mean      -0.000          0.000        0.000       -0.000            -0.000   \n",
       "std        1.000          1.000        1.000        1.000             1.000   \n",
       "min       -1.533         -2.790       -3.440       -0.319            -0.601   \n",
       "25%       -0.638         -0.765        0.427       -0.319            -0.601   \n",
       "50%       -0.204          0.248        0.427       -0.319            -0.601   \n",
       "75%        0.411          0.754        0.427       -0.319             1.662   \n",
       "max       17.262          1.767        2.360        3.129             1.662   \n",
       "\n",
       "       property_age  school_score  exterior_walls_Brick  \\\n",
       "count      1490.000      1490.000              1490.000   \n",
       "mean         -0.000        -0.000                 0.000   \n",
       "std           1.000         1.000                 1.000   \n",
       "min          -1.148        -2.018                -0.749   \n",
       "25%          -0.865        -0.777                -0.749   \n",
       "50%          -0.205        -0.127                -0.749   \n",
       "75%           0.644         0.818                 1.334   \n",
       "max           4.227         2.709                 1.334   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                     1490.000                    1490.000   \n",
       "mean                         0.000                       0.000   \n",
       "std                          1.000                       1.000   \n",
       "min                         -0.157                      -0.250   \n",
       "25%                         -0.157                      -0.250   \n",
       "50%                         -0.157                      -0.250   \n",
       "75%                         -0.157                      -0.250   \n",
       "max                          6.353                       3.990   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count              1490.000                1490.000              1490.000   \n",
       "mean                  0.000                   0.000                 0.000   \n",
       "std                   1.000                   1.000                 1.000   \n",
       "min                  -0.265                  -0.368                -0.198   \n",
       "25%                  -0.265                  -0.368                -0.198   \n",
       "50%                  -0.265                  -0.368                -0.198   \n",
       "75%                  -0.265                  -0.368                -0.198   \n",
       "max                   3.768                   2.714                 5.059   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                            1490.000             1490.000      1490.000   \n",
       "mean                                0.000               -0.000        -0.000   \n",
       "std                                 1.000                1.000         1.000   \n",
       "min                                -0.606               -0.265        -0.281   \n",
       "25%                                -0.606               -0.265        -0.281   \n",
       "50%                                -0.606               -0.265        -0.281   \n",
       "75%                                 1.650               -0.265        -0.281   \n",
       "max                                 1.650                3.768         3.558   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing  roof_Other  roof_Shake Shingle  \\\n",
       "count                  1490.000      1490.000    1490.000            1490.000   \n",
       "mean                     -0.000         0.000      -0.000               0.000   \n",
       "std                       1.000         1.000       1.000               1.000   \n",
       "min                      -1.343        -0.483      -0.253              -0.186   \n",
       "25%                      -1.343        -0.483      -0.253              -0.186   \n",
       "50%                       0.744        -0.483      -0.253              -0.186   \n",
       "75%                       0.744        -0.483      -0.253              -0.186   \n",
       "max                       0.744         2.069       3.943               5.365   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                     1490.000   \n",
       "mean                                         0.000   \n",
       "std                                          1.000   \n",
       "min                                         -0.850   \n",
       "25%                                         -0.850   \n",
       "50%                                         -0.850   \n",
       "75%                                          1.176   \n",
       "max                                          1.176   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                     1490.000  \n",
       "mean                        -0.000  \n",
       "std                          1.000  \n",
       "min                         -1.176  \n",
       "25%                         -1.176  \n",
       "50%                          0.850  \n",
       "75%                          0.850  \n",
       "max                          0.850  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual standardization\n",
    "X_train_new = (X_train - X_train.mean()) / X_train.std()\n",
    "X_train_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Standardizing test data\n",
    "\n",
    "X_test_new = (X_test - X_train.mean())/X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>property_age</th>\n",
       "      <th>school_score</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.989</td>\n",
       "      <td>1.002</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.988</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.034</td>\n",
       "      <td>1.078</td>\n",
       "      <td>1.121</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.019</td>\n",
       "      <td>0.922</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.908</td>\n",
       "      <td>1.043</td>\n",
       "      <td>0.895</td>\n",
       "      <td>1.068</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.972</td>\n",
       "      <td>1.030</td>\n",
       "      <td>1.018</td>\n",
       "      <td>1.150</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.051</td>\n",
       "      <td>0.853</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.269</td>\n",
       "      <td>-1.697</td>\n",
       "      <td>-1.261</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>-1.740</td>\n",
       "      <td>-2.843</td>\n",
       "      <td>-2.692</td>\n",
       "      <td>-1.396</td>\n",
       "      <td>-1.295</td>\n",
       "      <td>-2.790</td>\n",
       "      <td>-3.440</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-1.148</td>\n",
       "      <td>-2.018</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.804</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.628</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>-0.678</td>\n",
       "      <td>-0.703</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.912</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>1.662</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.818</td>\n",
       "      <td>1.334</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>1.650</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.459</td>\n",
       "      <td>3.676</td>\n",
       "      <td>4.128</td>\n",
       "      <td>12.149</td>\n",
       "      <td>0.372</td>\n",
       "      <td>4.821</td>\n",
       "      <td>3.915</td>\n",
       "      <td>5.804</td>\n",
       "      <td>5.349</td>\n",
       "      <td>5.741</td>\n",
       "      <td>6.741</td>\n",
       "      <td>5.912</td>\n",
       "      <td>4.013</td>\n",
       "      <td>4.156</td>\n",
       "      <td>1.537</td>\n",
       "      <td>1.988</td>\n",
       "      <td>4.791</td>\n",
       "      <td>5.375</td>\n",
       "      <td>1.767</td>\n",
       "      <td>2.360</td>\n",
       "      <td>3.129</td>\n",
       "      <td>1.662</td>\n",
       "      <td>3.284</td>\n",
       "      <td>2.709</td>\n",
       "      <td>1.334</td>\n",
       "      <td>6.353</td>\n",
       "      <td>3.990</td>\n",
       "      <td>3.768</td>\n",
       "      <td>2.714</td>\n",
       "      <td>5.059</td>\n",
       "      <td>1.650</td>\n",
       "      <td>3.768</td>\n",
       "      <td>3.558</td>\n",
       "      <td>0.744</td>\n",
       "      <td>2.069</td>\n",
       "      <td>3.943</td>\n",
       "      <td>5.365</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         beds   baths    sqft  lot_size  basement  restaurants  groceries  \\\n",
       "count 373.000 373.000 373.000   373.000   373.000      373.000    373.000   \n",
       "mean   -0.117  -0.081  -0.091    -0.032     0.011        0.091      0.141   \n",
       "std     0.959   0.989   1.002     1.034     0.988        1.004      0.996   \n",
       "min    -2.269  -1.697  -1.261    -0.366    -2.688       -0.841     -0.976   \n",
       "25%    -0.405  -0.622  -0.804    -0.325     0.372       -0.628     -0.753   \n",
       "50%    -0.405  -0.622  -0.387    -0.266     0.372       -0.287     -0.086   \n",
       "75%     0.527   0.452   0.306    -0.063     0.372        0.500      0.581   \n",
       "max     1.459   3.676   4.128    12.149     0.372        4.821      3.915   \n",
       "\n",
       "       nightlife   cafes  shopping  arts_entertainment  beauty_spas  \\\n",
       "count    373.000 373.000   373.000             373.000      373.000   \n",
       "mean       0.057   0.109     0.132               0.048        0.108   \n",
       "std        1.034   1.078     1.121               1.013        1.019   \n",
       "min       -0.593  -0.697    -0.756              -0.716       -0.891   \n",
       "25%       -0.474  -0.562    -0.565              -0.716       -0.657   \n",
       "50%       -0.356  -0.294    -0.259              -0.290       -0.230   \n",
       "75%        0.118   0.244     0.333               0.349        0.587   \n",
       "max        5.804   5.349     5.741               6.741        5.912   \n",
       "\n",
       "       active_life  median_age  married  college_grad  property_tax  \\\n",
       "count      373.000     373.000  373.000       373.000       373.000   \n",
       "mean         0.035       0.072   -0.101         0.010        -0.064   \n",
       "std          0.922       1.021    0.949         0.945         0.890   \n",
       "min         -0.876      -1.740   -2.843        -2.692        -1.396   \n",
       "25%         -0.543      -0.682   -0.678        -0.703        -0.652   \n",
       "50%         -0.265      -0.077    0.077         0.058        -0.243   \n",
       "75%          0.346       0.679    0.631         0.760         0.267   \n",
       "max          4.013       4.156    1.537         1.988         4.791   \n",
       "\n",
       "       insurance  median_school  num_schools  two_and_two  during_recession  \\\n",
       "count    373.000        373.000      373.000      373.000           373.000   \n",
       "mean      -0.055         -0.036        0.121        0.050            -0.025   \n",
       "std        0.908          1.043        0.895        1.068             0.987   \n",
       "min       -1.295         -2.790       -3.440       -0.319            -0.601   \n",
       "25%       -0.666         -0.765        0.427       -0.319            -0.601   \n",
       "50%       -0.246          0.248        0.427       -0.319            -0.601   \n",
       "75%        0.271          0.754        0.427       -0.319             1.662   \n",
       "max        5.375          1.767        2.360        3.129             1.662   \n",
       "\n",
       "       property_age  school_score  exterior_walls_Brick  \\\n",
       "count       373.000       373.000               373.000   \n",
       "mean          0.013         0.064                 0.066   \n",
       "std           0.972         1.030                 1.018   \n",
       "min          -1.148        -2.018                -0.749   \n",
       "25%          -0.912        -0.600                -0.749   \n",
       "50%          -0.158        -0.127                -0.749   \n",
       "75%           0.691         0.818                 1.334   \n",
       "max           3.284         2.709                 1.334   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                      373.000                     373.000   \n",
       "mean                         0.052                      -0.046   \n",
       "std                          1.150                       0.910   \n",
       "min                         -0.157                      -0.250   \n",
       "25%                         -0.157                      -0.250   \n",
       "50%                         -0.157                      -0.250   \n",
       "75%                         -0.157                      -0.250   \n",
       "max                          6.353                       3.990   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count               373.000                 373.000               373.000   \n",
       "mean                 -0.027                  -0.005                -0.043   \n",
       "std                   0.951                   0.996                 0.890   \n",
       "min                  -0.265                  -0.368                -0.198   \n",
       "25%                  -0.265                  -0.368                -0.198   \n",
       "50%                  -0.265                  -0.368                -0.198   \n",
       "75%                  -0.265                  -0.368                -0.198   \n",
       "max                   3.768                   2.714                 5.059   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                             373.000              373.000       373.000   \n",
       "mean                               -0.025               -0.006        -0.003   \n",
       "std                                 0.988                0.991         0.996   \n",
       "min                                -0.606               -0.265        -0.281   \n",
       "25%                                -0.606               -0.265        -0.281   \n",
       "50%                                -0.606               -0.265        -0.281   \n",
       "75%                                 1.650               -0.265        -0.281   \n",
       "max                                 1.650                3.768         3.558   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing  roof_Other  roof_Shake Shingle  \\\n",
       "count                   373.000       373.000     373.000             373.000   \n",
       "mean                      0.011        -0.004       0.028              -0.052   \n",
       "std                       0.998         0.998       1.051               0.853   \n",
       "min                      -1.343        -0.483      -0.253              -0.186   \n",
       "25%                      -1.343        -0.483      -0.253              -0.186   \n",
       "50%                       0.744        -0.483      -0.253              -0.186   \n",
       "75%                       0.744        -0.483      -0.253              -0.186   \n",
       "max                       0.744         2.069       3.943               5.365   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                      373.000   \n",
       "mean                                         0.112   \n",
       "std                                          1.013   \n",
       "min                                         -0.850   \n",
       "25%                                         -0.850   \n",
       "50%                                         -0.850   \n",
       "75%                                          1.176   \n",
       "max                                          1.176   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                      373.000  \n",
       "mean                        -0.112  \n",
       "std                          1.013  \n",
       "min                         -1.176  \n",
       "25%                         -1.176  \n",
       "50%                          0.850  \n",
       "75%                          0.850  \n",
       "max                          0.850  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model pipeline nd crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model pipeline\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Library for standardization\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=123,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_pipeline(StandardScaler(), Lasso(random_state=123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create pipeline dictionary\n",
    "\n",
    "pipelines = {\n",
    "    'lasso' : make_pipeline(StandardScaler(), Lasso(random_state=123)),\n",
    "    'ridge' : make_pipeline(StandardScaler(), Ridge(random_state=123))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline for elasticnet\n",
    "pipelines['enet'] = make_pipeline(StandardScaler(), ElasticNet(random_state=123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a pipeline for 'rf'\n",
    "pipelines['rf'] = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=123))\n",
    "\n",
    "# Add a pipeline for 'gb'\n",
    "pipelines['gb'] = make_pipeline(StandardScaler(), GradientBoostingRegressor(random_state=123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso <class 'sklearn.pipeline.Pipeline'>\n",
      "ridge <class 'sklearn.pipeline.Pipeline'>\n",
      "enet <class 'sklearn.pipeline.Pipeline'>\n",
      "rf <class 'sklearn.pipeline.Pipeline'>\n",
      "gb <class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "for key, value in pipelines.items():\n",
    "    print(key, type(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Hyperparameters to tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lasso': Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "    normalize=False, positive=False, precompute=False, random_state=123,\n",
       "    selection='cyclic', tol=0.0001, warm_start=False),\n",
       " 'lasso__alpha': 1.0,\n",
       " 'lasso__copy_X': True,\n",
       " 'lasso__fit_intercept': True,\n",
       " 'lasso__max_iter': 1000,\n",
       " 'lasso__normalize': False,\n",
       " 'lasso__positive': False,\n",
       " 'lasso__precompute': False,\n",
       " 'lasso__random_state': 123,\n",
       " 'lasso__selection': 'cyclic',\n",
       " 'lasso__tol': 0.0001,\n",
       " 'lasso__warm_start': False,\n",
       " 'memory': None,\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=123,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False))]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List tuneable hyperparameters of our Lasso pipeline\n",
    "pipelines['lasso'].get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lasso hyperparameters\n",
    "lasso_hyperparameters = { \n",
    "    'lasso__alpha' : [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10] \n",
    "}\n",
    "\n",
    "# Ridge hyperparameters\n",
    "ridge_hyperparameters = { \n",
    "    'ridge__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Elastic Net hyperparameters\n",
    "enet_hyperparameters = { \n",
    "    'elasticnet__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],                        \n",
    "    'elasticnet__l1_ratio' : [0.1, 0.3, 0.5, 0.7, 0.9]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random forest hyperparameters\n",
    "rf_hyperparameters = { \n",
    "    'randomforestregressor__n_estimators' : [100, 200],\n",
    "    'randomforestregressor__max_features': ['auto', 'sqrt', 0.33],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Boosted tree hyperparameters\n",
    "gb_hyperparameters = { \n",
    "    'gradientboostingregressor__n_estimators': [100, 200],\n",
    "    'gradientboostingregressor__learning_rate' : [0.05, 0.1, 0.2],\n",
    "    'gradientboostingregressor__max_depth': [1, 3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gradientboostingregressor': GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "              max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "              min_impurity_split=None, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=123,\n",
       "              subsample=1.0, verbose=0, warm_start=False),\n",
       " 'gradientboostingregressor__alpha': 0.9,\n",
       " 'gradientboostingregressor__criterion': 'friedman_mse',\n",
       " 'gradientboostingregressor__init': None,\n",
       " 'gradientboostingregressor__learning_rate': 0.1,\n",
       " 'gradientboostingregressor__loss': 'ls',\n",
       " 'gradientboostingregressor__max_depth': 3,\n",
       " 'gradientboostingregressor__max_features': None,\n",
       " 'gradientboostingregressor__max_leaf_nodes': None,\n",
       " 'gradientboostingregressor__min_impurity_decrease': 0.0,\n",
       " 'gradientboostingregressor__min_impurity_split': None,\n",
       " 'gradientboostingregressor__min_samples_leaf': 1,\n",
       " 'gradientboostingregressor__min_samples_split': 2,\n",
       " 'gradientboostingregressor__min_weight_fraction_leaf': 0.0,\n",
       " 'gradientboostingregressor__n_estimators': 100,\n",
       " 'gradientboostingregressor__presort': 'auto',\n",
       " 'gradientboostingregressor__random_state': 123,\n",
       " 'gradientboostingregressor__subsample': 1.0,\n",
       " 'gradientboostingregressor__verbose': 0,\n",
       " 'gradientboostingregressor__warm_start': False,\n",
       " 'memory': None,\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('gradientboostingregressor',\n",
       "   GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "                max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                min_impurity_split=None, min_samples_leaf=1,\n",
       "                min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                n_estimators=100, presort='auto', random_state=123,\n",
       "                subsample=1.0, verbose=0, warm_start=False))]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines['gb'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lasso', 'ridge', 'enet', 'rf', 'gb'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create hyperparameters dictionary\n",
    "hyperparameters = {\n",
    "    'rf' : rf_hyperparameters,\n",
    "    'gb' : gb_hyperparameters,\n",
    "    'lasso' : lasso_hyperparameters,\n",
    "    'ridge' : ridge_hyperparameters,\n",
    "    'enet' : enet_hyperparameters\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet was found in hyperparameters, and it is a grid.\n",
      "gb was found in hyperparameters, and it is a grid.\n",
      "ridge was found in hyperparameters, and it is a grid.\n",
      "rf was found in hyperparameters, and it is a grid.\n",
      "lasso was found in hyperparameters, and it is a grid.\n"
     ]
    }
   ],
   "source": [
    "for key in ['enet', 'gb', 'ridge', 'rf', 'lasso']:\n",
    "    if key in hyperparameters:\n",
    "        if type(hyperparameters[key]) is dict:\n",
    "            print( key, 'was found in hyperparameters, and it is a grid.' )\n",
    "        else:\n",
    "            print( key, 'was found in hyperparameters, but it is not a grid.' )\n",
    "    else:\n",
    "        print( key, 'was not found in hyperparameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper for cross-validation\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create cross-validation object from Lasso pipeline and Lasso hyperparameters\n",
    "model = GridSearchCV(pipelines['lasso'], hyperparameters['lasso'], cv=10, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.model_selection._search.GridSearchCV"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=123,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and tune model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted.\n",
      "ridge has been fitted.\n",
      "enet has been fitted.\n",
      "rf has been fitted.\n",
      "gb has been fitted.\n"
     ]
    }
   ],
   "source": [
    "# Create empty dictionary called fitted_models\n",
    "fitted_models = {}\n",
    "\n",
    "# Loop through model pipelines, tuning each one and saving it to fitted_models\n",
    "for name, pipeline in pipelines.items():\n",
    "    # Create cross-validation object from pipeline and hyperparameters\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv=10, n_jobs=-1)\n",
    "    \n",
    "    # Fit model on X_train, y_train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Store model in fitted_models[name] \n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    # Print '{name} has been fitted'\n",
    "    print(name, 'has been fitted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "ridge <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "enet <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "rf <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "gb <class 'sklearn.model_selection._search.GridSearchCV'>\n"
     ]
    }
   ],
   "source": [
    "# Check that we have 5 cross-validation objects\n",
    "for key, value in fitted_models.items():\n",
    "    print(key, type(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted.\n",
      "ridge has been fitted.\n",
      "enet has been fitted.\n",
      "rf has been fitted.\n",
      "gb has been fitted.\n"
     ]
    }
   ],
   "source": [
    "    from sklearn.exceptions import NotFittedError\n",
    "    \n",
    "    for name, model in fitted_models.items():\n",
    "        try:\n",
    "            pred = model.predict(X_test)\n",
    "            print(name, 'has been fitted.')\n",
    "        except NotFittedError as e:\n",
    "            print(repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models and select winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validated training performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso 0.309321321129\n",
      "ridge 0.316805719351\n",
      "enet 0.342759786956\n",
      "rf 0.480576134721\n",
      "gb 0.48873808731\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    print(name, model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holdout R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To calculate R2 on the test set, we can import the r2_score() function\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean absolute error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decr...timators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=123, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'randomforestregressor__n_estimators': [100, 200], 'randomforestregressor__max_features': ['auto', 'sqrt', 0.33]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display fitted random forest object\n",
    "fitted_models['rf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict test set using fitted random forest\n",
    "pred = fitted_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.568539460227\n",
      "MAE: 68211.829008\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print R^2 and MAE\n",
    "print('R^2:', r2_score(y_test, pred))\n",
    "print('MAE:', mean_absolute_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso\n",
      "---------\n",
      "R^2: 0.409313458932\n",
      "MAE: 84963.5598922\n",
      "\n",
      "ridge\n",
      "---------\n",
      "R^2: 0.409681314445\n",
      "MAE: 84923.9964122\n",
      "\n",
      "enet\n",
      "---------\n",
      "R^2: 0.405913076758\n",
      "MAE: 86249.5773005\n",
      "\n",
      "rf\n",
      "---------\n",
      "R^2: 0.568539460227\n",
      "MAE: 68211.829008\n",
      "\n",
      "gb\n",
      "---------\n",
      "R^2: 0.534407277273\n",
      "MAE: 70828.5758031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    pred = model.predict(X_test)\n",
    "    print(name)\n",
    "    print('---------')\n",
    "    print('R^2:', r2_score(y_test, pred))\n",
    "    print('MAE:', mean_absolute_error(y_test, pred))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot performance ofwinning model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c84315ca90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_pred = fitted_models['rf'].predict(X_test)\n",
    "plt.scatter(rf_pred, y_test)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save winning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.model_selection._search.GridSearchCV"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fitted_models['rf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fitted_models['rf'].best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "           oob_score=False, random_state=123, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_models['rf'].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('project_files/final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(fitted_models['rf'].best_estimator_, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
